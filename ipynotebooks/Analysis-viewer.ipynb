{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from xml.etree import ElementTree\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from pyclustertend import hopkins, vat, assess_tendency_by_mean_metric_score\n",
    "from sklearn.preprocessing import scale, StandardScaler, MinMaxScaler, minmax_scale, RobustScaler,robust_scale\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as compute_metrics\n",
    "from sklearn.metrics.cluster import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cov_file = None\n",
    "\n",
    "true_labels = None\n",
    "\n",
    "save_to_folder = \"/classification/plots/\"\n",
    "\n",
    "def get_labelled_data():\n",
    "    file = \"/classification/all_labels.csv\"\n",
    "    data = pd.read_csv(file, sep=';')\n",
    "    return data\n",
    "\n",
    "complete_data_labels = pd.read_csv(\"/classification/init_all_labels.csv\", sep=';')\n",
    "\n",
    "all_labels = get_labelled_data()\n",
    "all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_columns = all_labels.columns.tolist()\n",
    "str_cols = ['Method', 'CLevel_threshold', 'CLevel_k_means', 'CLevel_em']\n",
    "list_columns = [col for col in list_columns if col not in str_cols]\n",
    "list_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "if true_labels is not None:\n",
    "    df_true_labells = pd.read_csv(true_labels, sep=';')\n",
    "    df_true_labells = df_true_labells[['Method', 'CLevel']]\n",
    "    df = pd.merge(df_true_labells, all_labels, how='left', on='Method')\n",
    "    df = df[['Method', 'LOC', 'CC', 'NP', 'NV', 'NEST', 'Ca', 'Ce', 'NChg',\n",
    "           'NCall', 'CLevel', 'CLevel_threshold', 'CLevel_k_means', 'CLevel_em']] sep=';', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = all_labels.copy()\n",
    "\n",
    "for col_name in list_columns:\n",
    "    col = scaled_data[col_name]\n",
    "    min_col, max_col = col.min(), col.max()\n",
    "#     min_col = 0  # consider min as 0 to perserve the importance of values; eg LOC 25, 50 -> 0.5, 1 \n",
    "#     print(col_name, min_col, max_col)\n",
    "    scaled_data[col_name] = (col - min_col) / (max_col - min_col)\n",
    "    \n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data[list_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sh_list_columns = ['LOC', 'NP', 'Ca', 'Ce', 'NChg']\n",
    "X = all_labels[list_columns]\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "# X_scaled = scaled_data[list_columns]\n",
    "\n",
    "features = X_scaled.T\n",
    "cov_matrix = np.cov(features)\n",
    "\n",
    "values, vectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "importance = {}\n",
    "explained_variances = []\n",
    "for i in range(len(values)):\n",
    "    val = values[i] / np.sum(values)\n",
    "    explained_variances.append(val)\n",
    "    importance[val] = list_columns[i]\n",
    " \n",
    "print(np.sum(explained_variances), '\\n', explained_variances)\n",
    "dict_keys = list(importance.keys())\n",
    "dict_keys.sort(reverse = True)\n",
    "all_in_order = \"\"\n",
    "for k in dict_keys:\n",
    "    all_in_order += importance[k] + \"  \"\n",
    "print(all_in_order)\n",
    "print(dict_keys)\n",
    "\n",
    "projected_1 = X_scaled.dot(vectors.T[0])\n",
    "projected_2 = X_scaled.dot(vectors.T[1])\n",
    "res = pd.DataFrame(projected_1, columns=['PC1'])\n",
    "res['PC2'] = projected_2\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(5,5))\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18,5))\n",
    "ax= axes.flatten()\n",
    "clvls = ['CLevel_threshold', 'CLevel_k_means', 'CLevel_em']\n",
    "titles = ['Threshold', 'K-means', 'EM']\n",
    "for i in range(3):\n",
    "    lvl = clvls[i]\n",
    "    sns.scatterplot(x=res['PC1'], y=res['PC2'], hue=all_labels[lvl],\n",
    "              palette={'low':'blue', 'regular':'#DCB732', 'high':'red'},\n",
    "              hue_order=[ \"high\", \"regular\",\"low\"], s=20, ax=ax[i])\n",
    "    ax[i].legend(loc=\"lower left\", title=titles[i])\n",
    "#     ax[i].set_ylabel(col_name)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# fig.suptitle('Clustering results on the first two principal components')\n",
    "plt.savefig(save_to_folder + 'pca.pdf', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = ['LOC',  'NP', 'Ca', 'Ce', 'NChg']\n",
    "\n",
    "temp_df = pd.DataFrame()\n",
    "temp_df[\"CRank\"] = scaled_data[metrics_list].sum(axis=1)\n",
    "temp_df = temp_df.sort_values(by='CRank', ignore_index=True)\n",
    "n = temp_df.shape[0]\n",
    "first_cut = round(n*0.7)\n",
    "second_cut = round(n*0.9)\n",
    "\n",
    "print(first_cut, second_cut, n)\n",
    "\n",
    "temp_df.loc[:first_cut, \"CLevel\"] = \"low\"\n",
    "temp_df.loc[first_cut:second_cut, \"CLevel\"] = \"regular\"\n",
    "temp_df.loc[second_cut:, \"CLevel\"] = \"high\"\n",
    "print(temp_df.describe())\n",
    "grouped_temp_df = temp_df.groupby('CLevel')\n",
    "grouped_temp_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = scaled_data.copy()\n",
    "df = pd.melt(df, id_vars=str_cols, value_vars=list_columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lvl in ['CLevel_threshold', 'CLevel_k_means', 'CLevel_em']:\n",
    "    print(lvl)\n",
    "    l1 = complete_data_labels[lvl]\n",
    "    l2 = all_labels[lvl]\n",
    "    \n",
    "    ari = adjusted_rand_score(l1, l2)\n",
    "    pr = compute_metrics.precision_score(l1, l2, labels=['high', 'regular', 'low'], average=None)\n",
    "    acc = compute_metrics.accuracy_score(l1, l2)\n",
    "    recall = compute_metrics.recall_score(l1, l2, labels=['high', 'regular', 'low'], average=None)\n",
    "    print('ari: {}  precision: {}, recall: {} accuracy: {}'.format(ari, pr, recall, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data_labels['CLevel_threshold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,7), dpi= 80)    \n",
    "sns.stripplot(data=df, x='variable', y='value', hue='CLevel_threshold',\n",
    "              palette={'low':'blue', 'regular':'#DCB732', 'high':'red'},\n",
    "              hue_order=[\"low\", \"regular\", \"high\"],\n",
    "              jitter=0.25, size=5, ax=ax, linewidth=.3, dodge=True)\n",
    "# plt.title('Results for the threshold approach')\n",
    "# plt.show()\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.savefig(save_to_folder + 'threshold.pdf', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,7), dpi= 80)    \n",
    "sns.stripplot(data=df, x='variable', y='value', hue='CLevel_k_means',\n",
    "              palette={'low':'blue', 'regular':'#DCB732', 'high':'red'},\n",
    "              hue_order=[\"low\", \"regular\", \"high\"],\n",
    "              jitter=0.25, size=5, ax=ax, linewidth=.3, dodge=True)\n",
    "# plt.title('Results for the K-means algorithm')\n",
    "# plt.show()\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "\n",
    "plt.savefig(save_to_folder + 'k-means.pdf', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,7), dpi= 80)    \n",
    "sns.stripplot(data=df, x='variable', y='value', hue='CLevel_em',\n",
    "              palette={'low':'blue', 'regular':'#DCB732', 'high':'red'},\n",
    "              hue_order=[\"low\", \"regular\", \"high\"],\n",
    "              jitter=0.25, size=5, ax=ax, linewidth=.3, dodge=True)\n",
    "# plt.title('Results for the EM algorithm')\n",
    "# plt.show()\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.savefig(save_to_folder + 'em.pdf', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_cov_file is None:\n",
    "    test_data = pd.DataFrame(columns = ['Method', 'CoveredStatements', 'TotalStatements'])\n",
    "else:\n",
    "    test_data = pd.read_csv(test_cov_file, sep=';')\n",
    "\n",
    "data_combined = pd.merge(all_labels[str_cols], test_data, on='Method', how='left')\n",
    "\n",
    "data_combined.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pywaffle import Waffle\n",
    "\n",
    "print('Result for threshold approach')\n",
    "\n",
    "low_ = data_combined[data_combined['CLevel_threshold'] == \"low\"]\n",
    "regular_ = data_combined[data_combined['CLevel_threshold'] == \"regular\"]\n",
    "high_ = data_combined[data_combined['CLevel_threshold'] == \"high\"]\n",
    "\n",
    "if data_combined['TotalStatements'].sum() == 0:\n",
    "    l_p, r_p, h_p = 0, 0, 0\n",
    "else:\n",
    "    l_p = low_['CoveredStatements'].sum()/low_['TotalStatements'].sum()\n",
    "    r_p = regular_['CoveredStatements'].sum()/regular_['TotalStatements'].sum()\n",
    "    h_p = high_['CoveredStatements'].sum()/high_['TotalStatements'].sum()\n",
    "\n",
    "print('low: {}  regular: {}  high: {}  test coverage percetange'.format(l_p, r_p, h_p))\n",
    "\n",
    "data = {'Low critical': low_.shape[0], 'Regular critical': regular_.shape[0], 'High critical': high_.shape[0]}\n",
    "print('Methods number', data)\n",
    "\n",
    "fig = plt.figure(\n",
    "    FigureClass=Waffle, \n",
    "    rows=10, \n",
    "    values=data, \n",
    "    colors=(\"#232066\", \"#DCB732\", \"#983D3D\"),\n",
    "    labels=['Low critical', 'Regular critical', 'High critical'],\n",
    "    legend={'loc': 'lower left', 'bbox_to_anchor': (0, -0.4), 'ncol': len(data), 'framealpha': 0},\n",
    "    interval_ratio_x=0.5,\n",
    "    interval_ratio_y=0.5,\n",
    "    figsize=(20,10)\n",
    ")\n",
    "fig.gca().set_facecolor('#EEEEEE')\n",
    "fig.set_facecolor('#EEEEEE')\n",
    "plt.title('Result for threshold approach')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Result for k_means algorithm')\n",
    "\n",
    "low_ = data_combined[data_combined['CLevel_k_means'] == \"low\"]\n",
    "regular_ = data_combined[data_combined['CLevel_k_means'] == \"regular\"]\n",
    "high_ = data_combined[data_combined['CLevel_k_means'] == \"high\"]\n",
    "\n",
    "if data_combined['TotalStatements'].sum() == 0:\n",
    "    l_p, r_p, h_p = 0, 0, 0\n",
    "else:\n",
    "    l_p = low_['CoveredStatements'].sum()/low_['TotalStatements'].sum()\n",
    "    r_p = regular_['CoveredStatements'].sum()/regular_['TotalStatements'].sum()\n",
    "    h_p = high_['CoveredStatements'].sum()/high_['TotalStatements'].sum()\n",
    "print('low: {}  regular: {}  high: {}  test coverage percetange'.format(l_p, r_p, h_p))\n",
    "\n",
    "\n",
    "data = {'Low critical': low_.shape[0], 'Regular critical': regular_.shape[0], 'High critical': high_.shape[0]}\n",
    "print('Methods number', data)\n",
    "\n",
    "fig = plt.figure(\n",
    "    FigureClass=Waffle, \n",
    "    rows=10, \n",
    "    values=data, \n",
    "    colors=(\"#232066\", \"#DCB732\", \"#983D3D\"),\n",
    "    labels=['Low critical', 'Regular critical', 'High critical'],\n",
    "    legend={'loc': 'lower left', 'bbox_to_anchor': (0, -0.4), 'ncol': len(data), 'framealpha': 0},\n",
    "    interval_ratio_x=0.5,\n",
    "    interval_ratio_y=0.5,\n",
    "    figsize=(20,10)\n",
    ")\n",
    "fig.gca().set_facecolor('#EEEEEE')\n",
    "fig.set_facecolor('#EEEEEE')\n",
    "plt.title('Result for k_means algorithm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Result for EM algorithm')\n",
    "\n",
    "low_ = data_combined[data_combined['CLevel_em'] == \"low\"]\n",
    "regular_ = data_combined[data_combined['CLevel_em'] == \"regular\"]\n",
    "high_ = data_combined[data_combined['CLevel_em'] == \"high\"]\n",
    "\n",
    "if data_combined['TotalStatements'].sum() == 0:\n",
    "    l_p, r_p, h_p = 0, 0, 0\n",
    "else:\n",
    "    l_p = low_['CoveredStatements'].sum()/low_['TotalStatements'].sum()\n",
    "    r_p = regular_['CoveredStatements'].sum()/regular_['TotalStatements'].sum()\n",
    "    h_p = high_['CoveredStatements'].sum()/high_['TotalStatements'].sum()\n",
    "    \n",
    "print('low: {}  regular: {}  high: {}  test coverage percetange'.format(l_p, r_p, h_p))\n",
    "\n",
    "\n",
    "data = {'Low critical': low_.shape[0], 'Regular critical': regular_.shape[0], 'High critical': high_.shape[0]}\n",
    "print('Methods number', data)\n",
    "\n",
    "fig = plt.figure(\n",
    "    FigureClass=Waffle, \n",
    "    rows=10, \n",
    "    values=data, \n",
    "    colors=(\"#232066\", \"#DCB732\", \"#983D3D\"),\n",
    "    labels=['Low critical', 'Regular critical', 'High critical'],\n",
    "    legend={'loc': 'lower left', 'bbox_to_anchor': (0, -0.4), 'ncol': len(data), 'framealpha': 0},\n",
    "    interval_ratio_x=0.5,\n",
    "    interval_ratio_y=0.5,\n",
    "    figsize=(20,10)\n",
    ")\n",
    "fig.gca().set_facecolor('#EEEEEE')\n",
    "fig.set_facecolor('#EEEEEE')\n",
    "plt.title('Result for EM algorithm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = data_combined['CoveredStatements'].sum()/data_combined['TotalStatements'].sum()\n",
    "print('total coverage', total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = data_combined[data_combined['CLevel_threshold'] == \"low\"]\n",
    "r[data_combined['CLevel_k_means'] == \"low\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
